<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>USTool.utils.SegDataGenerator API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>USTool.utils.SegDataGenerator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from keras.preprocessing.image import *
from keras.applications.imagenet_utils import preprocess_input
from keras import backend as K
from PIL import Image
import numpy as np
import os


def center_crop(x, center_crop_size, data_format, **kwargs):
    if data_format == &#39;channels_first&#39;:
        centerh, centerw = x.shape[1] // 2, x.shape[2] // 2
    elif data_format == &#39;channels_last&#39;:
        centerh, centerw = x.shape[0] // 2, x.shape[1] // 2
    lh, lw = center_crop_size[0] // 2, center_crop_size[1] // 2
    rh, rw = center_crop_size[0] - lh, center_crop_size[1] - lw

    h_start, h_end = centerh - lh, centerh + rh
    w_start, w_end = centerw - lw, centerw + rw
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :]


def pair_center_crop(x, y, center_crop_size, data_format, **kwargs):
    if data_format == &#39;channels_first&#39;:
        centerh, centerw = x.shape[1] // 2, x.shape[2] // 2
    elif data_format == &#39;channels_last&#39;:
        centerh, centerw = x.shape[0] // 2, x.shape[1] // 2
    lh, lw = center_crop_size[0] // 2, center_crop_size[1] // 2
    rh, rw = center_crop_size[0] - lh, center_crop_size[1] - lw

    h_start, h_end = centerh - lh, centerh + rh
    w_start, w_end = centerw - lw, centerw + rw
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end], \
               y[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :], \
               y[h_start:h_end, w_start:w_end, :]


def random_crop(x, random_crop_size, data_format, sync_seed=None, **kwargs):
    np.random.seed(sync_seed)
    if data_format == &#39;channels_first&#39;:
        h, w = x.shape[1], x.shape[2]
    elif data_format == &#39;channels_last&#39;:
        h, w = x.shape[0], x.shape[1]
    rangeh = (h - random_crop_size[0]) // 2
    rangew = (w - random_crop_size[1]) // 2
    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)
    offsetw = 0 if rangew == 0 else np.random.randint(rangew)

    h_start, h_end = offseth, offseth + random_crop_size[0]
    w_start, w_end = offsetw, offsetw + random_crop_size[1]
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :]


def pair_random_crop(x, y, random_crop_size, data_format, sync_seed=None, **kwargs):
    np.random.seed(sync_seed)
    if data_format == &#39;channels_first&#39;:
        h, w = x.shape[1], x.shape[2]
    elif data_format == &#39;channels_last&#39;:
        h, w = x.shape[0], x.shape[1]
    rangeh = (h - random_crop_size[0]) // 2
    rangew = (w - random_crop_size[1]) // 2
    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)
    offsetw = 0 if rangew == 0 else np.random.randint(rangew)

    h_start, h_end = offseth, offseth + random_crop_size[0]
    w_start, w_end = offsetw, offsetw + random_crop_size[1]
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end], y[:, h_start:h_end, h_start:h_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :], y[h_start:h_end, w_start:w_end, :]


class SegDirectoryIterator(Iterator):
    &#39;&#39;&#39;
    Users need to ensure that all files exist.
    Label images should be png images where pixel values represents class number.

    find images -name *.jpg &gt; images.txt
    find labels -name *.png &gt; labels.txt

    for a file name 2011_002920.jpg, each row should contain 2011_002920

    file_path: location of train.txt, or val.txt in PASCAL VOC2012 format,
        listing image file path components without extension
    data_dir: location of image files referred to by file in file_path
    label_dir: location of label files
    data_suffix: image file extension, such as `.jpg` or `.png`
    label_suffix: label file suffix, such as `.png`, or `.npy`
    loss_shape: shape to use when applying loss function to the label data
    &#39;&#39;&#39;

    def __init__(self, file_path, seg_data_generator,
                 data_dir, data_suffix,
                 label_dir, label_suffix, classes, ignore_label=255,
                 crop_mode=&#39;none&#39;, label_cval=255, pad_size=None,
                 target_size=None, color_mode=&#39;rgb&#39;,
                 data_format=&#39;default&#39;, class_mode=&#39;sparse&#39;,
                 batch_size=1, shuffle=True, seed=None,
                 save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;jpeg&#39;,
                 loss_shape=None):
        if data_format == &#39;default&#39;:
            data_format = K.image_data_format()
        self.file_path = file_path
        self.data_dir = data_dir
        self.data_suffix = data_suffix
        self.label_suffix = label_suffix
        self.label_dir = label_dir
        self.classes = classes
        self.seg_data_generator = seg_data_generator
        self.target_size = tuple(target_size)
        self.ignore_label = ignore_label
        self.crop_mode = crop_mode
        self.label_cval = label_cval
        self.pad_size = pad_size
        if color_mode not in {&#39;rgb&#39;, &#39;grayscale&#39;}:
            raise ValueError(&#39;Invalid color mode:&#39;, color_mode,
                             &#39;; expected &#34;rgb&#34; or &#34;grayscale&#34;.&#39;)
        self.color_mode = color_mode
        self.data_format = data_format
        self.nb_label_ch = 1
        self.loss_shape = loss_shape

        if (self.label_suffix == &#39;.npy&#39;) or (self.label_suffix == &#39;npy&#39;):
            self.label_file_format = &#39;npy&#39;
        else:
            self.label_file_format = &#39;img&#39;
        if target_size:
            if self.color_mode == &#39;rgb&#39;:
                if self.data_format == &#39;channels_last&#39;:
                    self.image_shape = self.target_size + (3,)
                else:
                    self.image_shape = (3,) + self.target_size
            else:
                if self.data_format == &#39;channels_last&#39;:
                    self.image_shape = self.target_size + (1,)
                else:
                    self.image_shape = (1,) + self.target_size
            if self.data_format == &#39;channels_last&#39;:
                self.label_shape = self.target_size + (self.nb_label_ch,)
            else:
                self.label_shape = (self.nb_label_ch,) + self.target_size
        elif batch_size != 1:
            raise ValueError(
                &#39;Batch size must be 1 when target image size is undetermined&#39;)
        else:
            self.image_shape = None
            self.label_shape = None
        if class_mode not in {&#39;sparse&#39;, None}:
            raise ValueError(&#39;Invalid class_mode:&#39;, class_mode,
                             &#39;; expected one of &#39;
                             &#39;&#34;sparse&#34;, or None.&#39;)
        self.class_mode = class_mode
        if save_to_dir:
            self.palette = None
        self.save_to_dir = save_to_dir
        self.save_prefix = save_prefix
        self.save_format = save_format

        white_list_formats = {&#39;png&#39;, &#39;jpg&#39;, &#39;jpeg&#39;, &#39;bmp&#39;, &#39;npy&#39;}

        # build lists for data files and label files
        self.data_files = []
        self.label_files = []
        fp = open(file_path)
        lines = fp.readlines()
        fp.close()
        self.nb_sample = len(lines)
        for line in lines:
            line = line.strip(&#39;\n&#39;)
            self.data_files.append(line + data_suffix)
            self.label_files.append(line + label_suffix)
        super(SegDirectoryIterator, self).__init__(
            self.nb_sample, batch_size, shuffle, seed)

    def _get_batches_of_transformed_samples(self, index_array):
        &#34;&#34;&#34;Gets a batch of transformed samples.
        # Arguments
            index_array: array of sample indices to include in batch.
        # Returns
            A batch of transformed samples.
        &#34;&#34;&#34;
        current_batch_size = len(index_array)

        # The transformation of images is not under thread lock so it can be
        # done in parallel
        if self.target_size:
            # TODO(ahundt) make dtype properly configurable
            batch_x = np.zeros((current_batch_size,) + self.image_shape)
            if self.loss_shape is None and self.label_file_format is &#39;img&#39;:
                batch_y = np.zeros((current_batch_size,) + self.label_shape,
                                   dtype=int)
            elif self.loss_shape is None:
                batch_y = np.zeros((current_batch_size,) + self.label_shape)
            else:
                batch_y = np.zeros((current_batch_size,) + self.loss_shape,
                                   dtype=np.uint8)
        grayscale = self.color_mode == &#39;grayscale&#39;
        # build batch of image data and labels
        for i, j in enumerate(index_array):
            data_file = self.data_files[j]
            label_file = self.label_files[j]
            img_file_format = &#39;img&#39;
            img = load_img(os.path.join(self.data_dir, data_file),
                           grayscale=grayscale, target_size=None)
            label_filepath = os.path.join(self.label_dir, label_file)

            if self.label_file_format == &#39;npy&#39;:
                y = np.load(label_filepath)
            else:
                label = Image.open(label_filepath)
                if self.save_to_dir and self.palette is None:
                    self.palette = label.palette

            # do padding
            if self.target_size:
                if self.crop_mode != &#39;none&#39;:
                    x = img_to_array(img, data_format=self.data_format)
                    if self.label_file_format is not &#39;npy&#39;:
                        y = img_to_array(
                            label, data_format=self.data_format).astype(int)
                    img_w, img_h = img.size
                    if self.pad_size:
                        pad_w = max(self.pad_size[1] - img_w, 0)
                        pad_h = max(self.pad_size[0] - img_h, 0)
                    else:
                        pad_w = max(self.target_size[1] - img_w, 0)
                        pad_h = max(self.target_size[0] - img_h, 0)
                    if self.data_format == &#39;channels_first&#39;:
                        x = np.lib.pad(x, ((0, 0), (pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2)), &#39;constant&#39;, constant_values=0.)
                        y = np.lib.pad(y, ((0, 0), (pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2)),
                                       &#39;constant&#39;, constant_values=self.label_cval)
                    elif self.data_format == &#39;channels_last&#39;:
                        x = np.lib.pad(x, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)), &#39;constant&#39;, constant_values=0.)
                        y = np.lib.pad(y, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)), &#39;constant&#39;, constant_values=self.label_cval)
                else:
                    x = img_to_array(img.resize((self.target_size[1], self.target_size[0]),
                                                Image.BILINEAR),
                                     data_format=self.data_format)
                    if self.label_file_format is not &#39;npy&#39;:
                        y = img_to_array(label.resize((self.target_size[1], self.target_size[
                                         0]), Image.NEAREST), data_format=self.data_format).astype(int)
                    else:
                        print(&#39;ERROR: resize not implemented for label npy file&#39;)

            if self.target_size is None:
                batch_x = np.zeros((current_batch_size,) + x.shape)
                if self.loss_shape is not None:
                    batch_y = np.zeros((current_batch_size,) + self.loss_shape)
                else:
                    batch_y = np.zeros((current_batch_size,) + y.shape)

            x, y = self.seg_data_generator.random_transform(x, y)
            x = self.seg_data_generator.standardize(x)

            if self.ignore_label:
                y[np.where(y == self.ignore_label)] = self.classes

            if self.loss_shape is not None:
                y = np.reshape(y, self.loss_shape)

            batch_x[i] = x
            batch_y[i] = y
        # optionally save augmented images to disk for debugging purposes
        if self.save_to_dir:
            for i in range(current_batch_size):
                img = array_to_img(batch_x[i], self.data_format, scale=True)
                label = batch_y[i][:, :, 0].astype(&#39;uint8&#39;)
                label[np.where(label == self.classes)] = self.ignore_label
                label = Image.fromarray(label, mode=&#39;P&#39;)
                label.palette = self.palette
                # TODO(ahundt) fix index=i, a hacky workaround since current_index + i is no long available
                fname = &#39;{prefix}_{index}_{hash}&#39;.format(prefix=self.save_prefix,
                                                         index=i,
                                                         hash=np.random.randint(1e4))
                img.save(os.path.join(self.save_to_dir, &#39;img_&#39; +
                                      fname + &#39;.{format}&#39;.format(format=self.save_format)))
                label.save(os.path.join(self.save_to_dir,
                                        &#39;label_&#39; + fname + &#39;.png&#39;))
        # return
        batch_x = preprocess_input(batch_x)
        if self.class_mode == &#39;sparse&#39;:
            return batch_x, batch_y
        else:
            return batch_x


class SegDataGenerator(object):

    def __init__(self,
                 featurewise_center=False,
                 samplewise_center=False,
                 featurewise_std_normalization=False,
                 samplewise_std_normalization=False,
                 channelwise_center=False,
                 rotation_range=0.,
                 width_shift_range=0.,
                 height_shift_range=0.,
                 shear_range=0.,
                 zoom_range=0.,
                 zoom_maintain_shape=True,
                 channel_shift_range=0.,
                 fill_mode=&#39;constant&#39;,
                 cval=0.,
                 label_cval=255,
                 crop_mode=&#39;none&#39;,
                 crop_size=(0, 0),
                 pad_size=None,
                 horizontal_flip=False,
                 vertical_flip=False,
                 rescale=None,
                 data_format=&#39;default&#39;):
        if data_format == &#39;default&#39;:
            data_format = K.image_data_format()
        self.__dict__.update(locals())
        self.mean = None
        self.ch_mean = None
        self.std = None
        self.principal_components = None
        self.rescale = rescale

        if data_format not in {&#39;channels_last&#39;, &#39;channels_first&#39;}:
            raise Exception(&#39;data_format should be channels_last (channel after row and &#39;
                            &#39;column) or channels_first (channel before row and column). &#39;
                            &#39;Received arg: &#39;, data_format)
        if crop_mode not in {&#39;none&#39;, &#39;random&#39;, &#39;center&#39;}:
            raise Exception(&#39;crop_mode should be &#34;none&#34; or &#34;random&#34; or &#34;center&#34; &#39;
                            &#39;Received arg: &#39;, crop_mode)
        self.data_format = data_format
        if data_format == &#39;channels_first&#39;:
            self.channel_index = 1
            self.row_index = 2
            self.col_index = 3
        if data_format == &#39;channels_last&#39;:
            self.channel_index = 3
            self.row_index = 1
            self.col_index = 2

        if np.isscalar(zoom_range):
            self.zoom_range = [1 - zoom_range, 1 + zoom_range]
        elif len(zoom_range) == 2:
            self.zoom_range = [zoom_range[0], zoom_range[1]]
        else:
            raise Exception(&#39;zoom_range should be a float or &#39;
                            &#39;a tuple or list of two floats. &#39;
                            &#39;Received arg: &#39;, zoom_range)

    def flow_from_directory(self, file_path, data_dir, data_suffix,
                            label_dir, label_suffix, classes,
                            ignore_label=255,
                            target_size=None, color_mode=&#39;rgb&#39;,
                            class_mode=&#39;sparse&#39;,
                            batch_size=32, shuffle=True, seed=None,
                            save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;jpeg&#39;,
                            loss_shape=None):
        if self.crop_mode == &#39;random&#39; or self.crop_mode == &#39;center&#39;:
            target_size = self.crop_size
        return SegDirectoryIterator(
            file_path, self,
            data_dir=data_dir, data_suffix=data_suffix,
            label_dir=label_dir, label_suffix=label_suffix,
            classes=classes, ignore_label=ignore_label,
            crop_mode=self.crop_mode, label_cval=self.label_cval,
            pad_size=self.pad_size,
            target_size=target_size, color_mode=color_mode,
            data_format=self.data_format, class_mode=class_mode,
            batch_size=batch_size, shuffle=shuffle, seed=seed,
            save_to_dir=save_to_dir, save_prefix=save_prefix,
            save_format=save_format,
            loss_shape=loss_shape)

    def standardize(self, x):
        if self.rescale:
            x *= self.rescale
        # x is a single image, so it doesn&#39;t have image number at index 0
        img_channel_index = self.channel_index - 1
        if self.samplewise_center:
            x -= np.mean(x, axis=img_channel_index, keepdims=True)
        if self.samplewise_std_normalization:
            x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)

        if self.featurewise_center:
            x -= self.mean
        if self.featurewise_std_normalization:
            x /= (self.std + 1e-7)

        if self.channelwise_center:
            x -= self.ch_mean
        return x

    def random_transform(self, x, y):
        # x is a single image, so it doesn&#39;t have image number at index 0
        img_row_index = self.row_index - 1
        img_col_index = self.col_index - 1
        img_channel_index = self.channel_index - 1
        if self.crop_mode == &#39;none&#39;:
            crop_size = (x.shape[img_row_index], x.shape[img_col_index])
        else:
            crop_size = self.crop_size

        assert x.shape[img_row_index] == y.shape[img_row_index] and x.shape[img_col_index] == y.shape[
            img_col_index], &#39;DATA ERROR: Different shape of data and label!\ndata shape: %s, label shape: %s&#39; % (str(x.shape), str(y.shape))

        # use composition of homographies to generate final transform that
        # needs to be applied
        if self.rotation_range:
            theta = np.pi / 180 * \
                np.random.uniform(-self.rotation_range, self.rotation_range)
        else:
            theta = 0
        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],
                                    [np.sin(theta), np.cos(theta), 0],
                                    [0, 0, 1]])
        if self.height_shift_range:
            # * x.shape[img_row_index]
            tx = np.random.uniform(-self.height_shift_range,
                                   self.height_shift_range) * crop_size[0]
        else:
            tx = 0

        if self.width_shift_range:
            # * x.shape[img_col_index]
            ty = np.random.uniform(-self.width_shift_range,
                                   self.width_shift_range) * crop_size[1]
        else:
            ty = 0

        translation_matrix = np.array([[1, 0, tx],
                                       [0, 1, ty],
                                       [0, 0, 1]])
        if self.shear_range:
            shear = np.random.uniform(-self.shear_range, self.shear_range)
        else:
            shear = 0
        shear_matrix = np.array([[1, -np.sin(shear), 0],
                                 [0, np.cos(shear), 0],
                                 [0, 0, 1]])

        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:
            zx, zy = 1, 1
        else:
            zx, zy = np.random.uniform(
                self.zoom_range[0], self.zoom_range[1], 2)
        if self.zoom_maintain_shape:
            zy = zx
        zoom_matrix = np.array([[zx, 0, 0],
                                [0, zy, 0],
                                [0, 0, 1]])

        transform_matrix = np.dot(
            np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)

        h, w = x.shape[img_row_index], x.shape[img_col_index]
        transform_matrix = transform_matrix_offset_center(
            transform_matrix, h, w)

        x = apply_transform(x, transform_matrix, img_channel_index,
                            fill_mode=self.fill_mode, cval=self.cval)
        y = apply_transform(y, transform_matrix, img_channel_index,
                            fill_mode=&#39;constant&#39;, cval=self.label_cval)

        if self.channel_shift_range != 0:
            x = random_channel_shift(
                x, self.channel_shift_range, img_channel_index)

        if self.horizontal_flip:
            if np.random.random() &lt; 0.5:
                x = flip_axis(x, img_col_index)
                y = flip_axis(y, img_col_index)

        if self.vertical_flip:
            if np.random.random() &lt; 0.5:
                x = flip_axis(x, img_row_index)
                y = flip_axis(y, img_row_index)

        if self.crop_mode == &#39;center&#39;:
            x, y = pair_center_crop(x, y, self.crop_size, self.data_format)
        elif self.crop_mode == &#39;random&#39;:
            x, y = pair_random_crop(x, y, self.crop_size, self.data_format)

        # TODO:
        # channel-wise normalization
        # barrel/fisheye
        return x, y

    def fit(self, X,
            augment=False,
            rounds=1,
            seed=None):
        &#39;&#39;&#39;Required for featurewise_center and featurewise_std_normalization

        # Arguments
            X: Numpy array, the data to fit on.
            augment: whether to fit on randomly augmented samples
            rounds: if `augment`,
                how many augmentation passes to do over the data
            seed: random seed.
        &#39;&#39;&#39;
        X = np.copy(X)
        if augment:
            aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))
            for r in range(rounds):
                for i in range(X.shape[0]):
                    aX[i + r * X.shape[0]] = self.random_transform(X[i])
            X = aX

        if self.featurewise_center:
            self.mean = np.mean(X, axis=0)
            X -= self.mean

        if self.featurewise_std_normalization:
            self.std = np.std(X, axis=0)
            X /= (self.std + 1e-7)

    def set_ch_mean(self, ch_mean):
        self.ch_mean = ch_mean</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="USTool.utils.SegDataGenerator.center_crop"><code class="name flex">
<span>def <span class="ident">center_crop</span></span>(<span>x, center_crop_size, data_format, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def center_crop(x, center_crop_size, data_format, **kwargs):
    if data_format == &#39;channels_first&#39;:
        centerh, centerw = x.shape[1] // 2, x.shape[2] // 2
    elif data_format == &#39;channels_last&#39;:
        centerh, centerw = x.shape[0] // 2, x.shape[1] // 2
    lh, lw = center_crop_size[0] // 2, center_crop_size[1] // 2
    rh, rw = center_crop_size[0] - lh, center_crop_size[1] - lw

    h_start, h_end = centerh - lh, centerh + rh
    w_start, w_end = centerw - lw, centerw + rw
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :]</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.pair_center_crop"><code class="name flex">
<span>def <span class="ident">pair_center_crop</span></span>(<span>x, y, center_crop_size, data_format, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pair_center_crop(x, y, center_crop_size, data_format, **kwargs):
    if data_format == &#39;channels_first&#39;:
        centerh, centerw = x.shape[1] // 2, x.shape[2] // 2
    elif data_format == &#39;channels_last&#39;:
        centerh, centerw = x.shape[0] // 2, x.shape[1] // 2
    lh, lw = center_crop_size[0] // 2, center_crop_size[1] // 2
    rh, rw = center_crop_size[0] - lh, center_crop_size[1] - lw

    h_start, h_end = centerh - lh, centerh + rh
    w_start, w_end = centerw - lw, centerw + rw
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end], \
               y[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :], \
               y[h_start:h_end, w_start:w_end, :]</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.pair_random_crop"><code class="name flex">
<span>def <span class="ident">pair_random_crop</span></span>(<span>x, y, random_crop_size, data_format, sync_seed=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pair_random_crop(x, y, random_crop_size, data_format, sync_seed=None, **kwargs):
    np.random.seed(sync_seed)
    if data_format == &#39;channels_first&#39;:
        h, w = x.shape[1], x.shape[2]
    elif data_format == &#39;channels_last&#39;:
        h, w = x.shape[0], x.shape[1]
    rangeh = (h - random_crop_size[0]) // 2
    rangew = (w - random_crop_size[1]) // 2
    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)
    offsetw = 0 if rangew == 0 else np.random.randint(rangew)

    h_start, h_end = offseth, offseth + random_crop_size[0]
    w_start, w_end = offsetw, offsetw + random_crop_size[1]
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end], y[:, h_start:h_end, h_start:h_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :], y[h_start:h_end, w_start:w_end, :]</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.random_crop"><code class="name flex">
<span>def <span class="ident">random_crop</span></span>(<span>x, random_crop_size, data_format, sync_seed=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_crop(x, random_crop_size, data_format, sync_seed=None, **kwargs):
    np.random.seed(sync_seed)
    if data_format == &#39;channels_first&#39;:
        h, w = x.shape[1], x.shape[2]
    elif data_format == &#39;channels_last&#39;:
        h, w = x.shape[0], x.shape[1]
    rangeh = (h - random_crop_size[0]) // 2
    rangew = (w - random_crop_size[1]) // 2
    offseth = 0 if rangeh == 0 else np.random.randint(rangeh)
    offsetw = 0 if rangew == 0 else np.random.randint(rangew)

    h_start, h_end = offseth, offseth + random_crop_size[0]
    w_start, w_end = offsetw, offsetw + random_crop_size[1]
    if data_format == &#39;channels_first&#39;:
        return x[:, h_start:h_end, w_start:w_end]
    elif data_format == &#39;channels_last&#39;:
        return x[h_start:h_end, w_start:w_end, :]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator"><code class="flex name class">
<span>class <span class="ident">SegDataGenerator</span></span>
<span>(</span><span>featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, channelwise_center=False, rotation_range=0.0, width_shift_range=0.0, height_shift_range=0.0, shear_range=0.0, zoom_range=0.0, zoom_maintain_shape=True, channel_shift_range=0.0, fill_mode='constant', cval=0.0, label_cval=255, crop_mode='none', crop_size=(0, 0), pad_size=None, horizontal_flip=False, vertical_flip=False, rescale=None, data_format='default')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SegDataGenerator(object):

    def __init__(self,
                 featurewise_center=False,
                 samplewise_center=False,
                 featurewise_std_normalization=False,
                 samplewise_std_normalization=False,
                 channelwise_center=False,
                 rotation_range=0.,
                 width_shift_range=0.,
                 height_shift_range=0.,
                 shear_range=0.,
                 zoom_range=0.,
                 zoom_maintain_shape=True,
                 channel_shift_range=0.,
                 fill_mode=&#39;constant&#39;,
                 cval=0.,
                 label_cval=255,
                 crop_mode=&#39;none&#39;,
                 crop_size=(0, 0),
                 pad_size=None,
                 horizontal_flip=False,
                 vertical_flip=False,
                 rescale=None,
                 data_format=&#39;default&#39;):
        if data_format == &#39;default&#39;:
            data_format = K.image_data_format()
        self.__dict__.update(locals())
        self.mean = None
        self.ch_mean = None
        self.std = None
        self.principal_components = None
        self.rescale = rescale

        if data_format not in {&#39;channels_last&#39;, &#39;channels_first&#39;}:
            raise Exception(&#39;data_format should be channels_last (channel after row and &#39;
                            &#39;column) or channels_first (channel before row and column). &#39;
                            &#39;Received arg: &#39;, data_format)
        if crop_mode not in {&#39;none&#39;, &#39;random&#39;, &#39;center&#39;}:
            raise Exception(&#39;crop_mode should be &#34;none&#34; or &#34;random&#34; or &#34;center&#34; &#39;
                            &#39;Received arg: &#39;, crop_mode)
        self.data_format = data_format
        if data_format == &#39;channels_first&#39;:
            self.channel_index = 1
            self.row_index = 2
            self.col_index = 3
        if data_format == &#39;channels_last&#39;:
            self.channel_index = 3
            self.row_index = 1
            self.col_index = 2

        if np.isscalar(zoom_range):
            self.zoom_range = [1 - zoom_range, 1 + zoom_range]
        elif len(zoom_range) == 2:
            self.zoom_range = [zoom_range[0], zoom_range[1]]
        else:
            raise Exception(&#39;zoom_range should be a float or &#39;
                            &#39;a tuple or list of two floats. &#39;
                            &#39;Received arg: &#39;, zoom_range)

    def flow_from_directory(self, file_path, data_dir, data_suffix,
                            label_dir, label_suffix, classes,
                            ignore_label=255,
                            target_size=None, color_mode=&#39;rgb&#39;,
                            class_mode=&#39;sparse&#39;,
                            batch_size=32, shuffle=True, seed=None,
                            save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;jpeg&#39;,
                            loss_shape=None):
        if self.crop_mode == &#39;random&#39; or self.crop_mode == &#39;center&#39;:
            target_size = self.crop_size
        return SegDirectoryIterator(
            file_path, self,
            data_dir=data_dir, data_suffix=data_suffix,
            label_dir=label_dir, label_suffix=label_suffix,
            classes=classes, ignore_label=ignore_label,
            crop_mode=self.crop_mode, label_cval=self.label_cval,
            pad_size=self.pad_size,
            target_size=target_size, color_mode=color_mode,
            data_format=self.data_format, class_mode=class_mode,
            batch_size=batch_size, shuffle=shuffle, seed=seed,
            save_to_dir=save_to_dir, save_prefix=save_prefix,
            save_format=save_format,
            loss_shape=loss_shape)

    def standardize(self, x):
        if self.rescale:
            x *= self.rescale
        # x is a single image, so it doesn&#39;t have image number at index 0
        img_channel_index = self.channel_index - 1
        if self.samplewise_center:
            x -= np.mean(x, axis=img_channel_index, keepdims=True)
        if self.samplewise_std_normalization:
            x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)

        if self.featurewise_center:
            x -= self.mean
        if self.featurewise_std_normalization:
            x /= (self.std + 1e-7)

        if self.channelwise_center:
            x -= self.ch_mean
        return x

    def random_transform(self, x, y):
        # x is a single image, so it doesn&#39;t have image number at index 0
        img_row_index = self.row_index - 1
        img_col_index = self.col_index - 1
        img_channel_index = self.channel_index - 1
        if self.crop_mode == &#39;none&#39;:
            crop_size = (x.shape[img_row_index], x.shape[img_col_index])
        else:
            crop_size = self.crop_size

        assert x.shape[img_row_index] == y.shape[img_row_index] and x.shape[img_col_index] == y.shape[
            img_col_index], &#39;DATA ERROR: Different shape of data and label!\ndata shape: %s, label shape: %s&#39; % (str(x.shape), str(y.shape))

        # use composition of homographies to generate final transform that
        # needs to be applied
        if self.rotation_range:
            theta = np.pi / 180 * \
                np.random.uniform(-self.rotation_range, self.rotation_range)
        else:
            theta = 0
        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],
                                    [np.sin(theta), np.cos(theta), 0],
                                    [0, 0, 1]])
        if self.height_shift_range:
            # * x.shape[img_row_index]
            tx = np.random.uniform(-self.height_shift_range,
                                   self.height_shift_range) * crop_size[0]
        else:
            tx = 0

        if self.width_shift_range:
            # * x.shape[img_col_index]
            ty = np.random.uniform(-self.width_shift_range,
                                   self.width_shift_range) * crop_size[1]
        else:
            ty = 0

        translation_matrix = np.array([[1, 0, tx],
                                       [0, 1, ty],
                                       [0, 0, 1]])
        if self.shear_range:
            shear = np.random.uniform(-self.shear_range, self.shear_range)
        else:
            shear = 0
        shear_matrix = np.array([[1, -np.sin(shear), 0],
                                 [0, np.cos(shear), 0],
                                 [0, 0, 1]])

        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:
            zx, zy = 1, 1
        else:
            zx, zy = np.random.uniform(
                self.zoom_range[0], self.zoom_range[1], 2)
        if self.zoom_maintain_shape:
            zy = zx
        zoom_matrix = np.array([[zx, 0, 0],
                                [0, zy, 0],
                                [0, 0, 1]])

        transform_matrix = np.dot(
            np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)

        h, w = x.shape[img_row_index], x.shape[img_col_index]
        transform_matrix = transform_matrix_offset_center(
            transform_matrix, h, w)

        x = apply_transform(x, transform_matrix, img_channel_index,
                            fill_mode=self.fill_mode, cval=self.cval)
        y = apply_transform(y, transform_matrix, img_channel_index,
                            fill_mode=&#39;constant&#39;, cval=self.label_cval)

        if self.channel_shift_range != 0:
            x = random_channel_shift(
                x, self.channel_shift_range, img_channel_index)

        if self.horizontal_flip:
            if np.random.random() &lt; 0.5:
                x = flip_axis(x, img_col_index)
                y = flip_axis(y, img_col_index)

        if self.vertical_flip:
            if np.random.random() &lt; 0.5:
                x = flip_axis(x, img_row_index)
                y = flip_axis(y, img_row_index)

        if self.crop_mode == &#39;center&#39;:
            x, y = pair_center_crop(x, y, self.crop_size, self.data_format)
        elif self.crop_mode == &#39;random&#39;:
            x, y = pair_random_crop(x, y, self.crop_size, self.data_format)

        # TODO:
        # channel-wise normalization
        # barrel/fisheye
        return x, y

    def fit(self, X,
            augment=False,
            rounds=1,
            seed=None):
        &#39;&#39;&#39;Required for featurewise_center and featurewise_std_normalization

        # Arguments
            X: Numpy array, the data to fit on.
            augment: whether to fit on randomly augmented samples
            rounds: if `augment`,
                how many augmentation passes to do over the data
            seed: random seed.
        &#39;&#39;&#39;
        X = np.copy(X)
        if augment:
            aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))
            for r in range(rounds):
                for i in range(X.shape[0]):
                    aX[i + r * X.shape[0]] = self.random_transform(X[i])
            X = aX

        if self.featurewise_center:
            self.mean = np.mean(X, axis=0)
            X -= self.mean

        if self.featurewise_std_normalization:
            self.std = np.std(X, axis=0)
            X /= (self.std + 1e-7)

    def set_ch_mean(self, ch_mean):
        self.ch_mean = ch_mean</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, augment=False, rounds=1, seed=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Required for featurewise_center and featurewise_std_normalization</p>
<h1 id="arguments">Arguments</h1>
<pre><code>X: Numpy array, the data to fit on.
augment: whether to fit on randomly augmented samples
rounds: if &lt;code&gt;augment&lt;/code&gt;,
    how many augmentation passes to do over the data
seed: random seed.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X,
        augment=False,
        rounds=1,
        seed=None):
    &#39;&#39;&#39;Required for featurewise_center and featurewise_std_normalization

    # Arguments
        X: Numpy array, the data to fit on.
        augment: whether to fit on randomly augmented samples
        rounds: if `augment`,
            how many augmentation passes to do over the data
        seed: random seed.
    &#39;&#39;&#39;
    X = np.copy(X)
    if augment:
        aX = np.zeros(tuple([rounds * X.shape[0]] + list(X.shape)[1:]))
        for r in range(rounds):
            for i in range(X.shape[0]):
                aX[i + r * X.shape[0]] = self.random_transform(X[i])
        X = aX

    if self.featurewise_center:
        self.mean = np.mean(X, axis=0)
        X -= self.mean

    if self.featurewise_std_normalization:
        self.std = np.std(X, axis=0)
        X /= (self.std + 1e-7)</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator.flow_from_directory"><code class="name flex">
<span>def <span class="ident">flow_from_directory</span></span>(<span>self, file_path, data_dir, data_suffix, label_dir, label_suffix, classes, ignore_label=255, target_size=None, color_mode='rgb', class_mode='sparse', batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg', loss_shape=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def flow_from_directory(self, file_path, data_dir, data_suffix,
                        label_dir, label_suffix, classes,
                        ignore_label=255,
                        target_size=None, color_mode=&#39;rgb&#39;,
                        class_mode=&#39;sparse&#39;,
                        batch_size=32, shuffle=True, seed=None,
                        save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;jpeg&#39;,
                        loss_shape=None):
    if self.crop_mode == &#39;random&#39; or self.crop_mode == &#39;center&#39;:
        target_size = self.crop_size
    return SegDirectoryIterator(
        file_path, self,
        data_dir=data_dir, data_suffix=data_suffix,
        label_dir=label_dir, label_suffix=label_suffix,
        classes=classes, ignore_label=ignore_label,
        crop_mode=self.crop_mode, label_cval=self.label_cval,
        pad_size=self.pad_size,
        target_size=target_size, color_mode=color_mode,
        data_format=self.data_format, class_mode=class_mode,
        batch_size=batch_size, shuffle=shuffle, seed=seed,
        save_to_dir=save_to_dir, save_prefix=save_prefix,
        save_format=save_format,
        loss_shape=loss_shape)</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator.random_transform"><code class="name flex">
<span>def <span class="ident">random_transform</span></span>(<span>self, x, y)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_transform(self, x, y):
    # x is a single image, so it doesn&#39;t have image number at index 0
    img_row_index = self.row_index - 1
    img_col_index = self.col_index - 1
    img_channel_index = self.channel_index - 1
    if self.crop_mode == &#39;none&#39;:
        crop_size = (x.shape[img_row_index], x.shape[img_col_index])
    else:
        crop_size = self.crop_size

    assert x.shape[img_row_index] == y.shape[img_row_index] and x.shape[img_col_index] == y.shape[
        img_col_index], &#39;DATA ERROR: Different shape of data and label!\ndata shape: %s, label shape: %s&#39; % (str(x.shape), str(y.shape))

    # use composition of homographies to generate final transform that
    # needs to be applied
    if self.rotation_range:
        theta = np.pi / 180 * \
            np.random.uniform(-self.rotation_range, self.rotation_range)
    else:
        theta = 0
    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],
                                [np.sin(theta), np.cos(theta), 0],
                                [0, 0, 1]])
    if self.height_shift_range:
        # * x.shape[img_row_index]
        tx = np.random.uniform(-self.height_shift_range,
                               self.height_shift_range) * crop_size[0]
    else:
        tx = 0

    if self.width_shift_range:
        # * x.shape[img_col_index]
        ty = np.random.uniform(-self.width_shift_range,
                               self.width_shift_range) * crop_size[1]
    else:
        ty = 0

    translation_matrix = np.array([[1, 0, tx],
                                   [0, 1, ty],
                                   [0, 0, 1]])
    if self.shear_range:
        shear = np.random.uniform(-self.shear_range, self.shear_range)
    else:
        shear = 0
    shear_matrix = np.array([[1, -np.sin(shear), 0],
                             [0, np.cos(shear), 0],
                             [0, 0, 1]])

    if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:
        zx, zy = 1, 1
    else:
        zx, zy = np.random.uniform(
            self.zoom_range[0], self.zoom_range[1], 2)
    if self.zoom_maintain_shape:
        zy = zx
    zoom_matrix = np.array([[zx, 0, 0],
                            [0, zy, 0],
                            [0, 0, 1]])

    transform_matrix = np.dot(
        np.dot(np.dot(rotation_matrix, translation_matrix), shear_matrix), zoom_matrix)

    h, w = x.shape[img_row_index], x.shape[img_col_index]
    transform_matrix = transform_matrix_offset_center(
        transform_matrix, h, w)

    x = apply_transform(x, transform_matrix, img_channel_index,
                        fill_mode=self.fill_mode, cval=self.cval)
    y = apply_transform(y, transform_matrix, img_channel_index,
                        fill_mode=&#39;constant&#39;, cval=self.label_cval)

    if self.channel_shift_range != 0:
        x = random_channel_shift(
            x, self.channel_shift_range, img_channel_index)

    if self.horizontal_flip:
        if np.random.random() &lt; 0.5:
            x = flip_axis(x, img_col_index)
            y = flip_axis(y, img_col_index)

    if self.vertical_flip:
        if np.random.random() &lt; 0.5:
            x = flip_axis(x, img_row_index)
            y = flip_axis(y, img_row_index)

    if self.crop_mode == &#39;center&#39;:
        x, y = pair_center_crop(x, y, self.crop_size, self.data_format)
    elif self.crop_mode == &#39;random&#39;:
        x, y = pair_random_crop(x, y, self.crop_size, self.data_format)

    # TODO:
    # channel-wise normalization
    # barrel/fisheye
    return x, y</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator.set_ch_mean"><code class="name flex">
<span>def <span class="ident">set_ch_mean</span></span>(<span>self, ch_mean)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_ch_mean(self, ch_mean):
    self.ch_mean = ch_mean</code></pre>
</details>
</dd>
<dt id="USTool.utils.SegDataGenerator.SegDataGenerator.standardize"><code class="name flex">
<span>def <span class="ident">standardize</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standardize(self, x):
    if self.rescale:
        x *= self.rescale
    # x is a single image, so it doesn&#39;t have image number at index 0
    img_channel_index = self.channel_index - 1
    if self.samplewise_center:
        x -= np.mean(x, axis=img_channel_index, keepdims=True)
    if self.samplewise_std_normalization:
        x /= (np.std(x, axis=img_channel_index, keepdims=True) + 1e-7)

    if self.featurewise_center:
        x -= self.mean
    if self.featurewise_std_normalization:
        x /= (self.std + 1e-7)

    if self.channelwise_center:
        x -= self.ch_mean
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="USTool.utils.SegDataGenerator.SegDirectoryIterator"><code class="flex name class">
<span>class <span class="ident">SegDirectoryIterator</span></span>
<span>(</span><span>file_path, seg_data_generator, data_dir, data_suffix, label_dir, label_suffix, classes, ignore_label=255, crop_mode='none', label_cval=255, pad_size=None, target_size=None, color_mode='rgb', data_format='default', class_mode='sparse', batch_size=1, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='jpeg', loss_shape=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Users need to ensure that all files exist.
Label images should be png images where pixel values represents class number.</p>
<p>find images -name <em>.jpg &gt; images.txt
find labels -name </em>.png &gt; labels.txt</p>
<p>for a file name 2011_002920.jpg, each row should contain 2011_002920</p>
<p>file_path: location of train.txt, or val.txt in PASCAL VOC2012 format,
listing image file path components without extension
data_dir: location of image files referred to by file in file_path
label_dir: location of label files
data_suffix: image file extension, such as <code>.jpg</code> or <code>.png</code>
label_suffix: label file suffix, such as <code>.png</code>, or <code>.npy</code>
loss_shape: shape to use when applying loss function to the label data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SegDirectoryIterator(Iterator):
    &#39;&#39;&#39;
    Users need to ensure that all files exist.
    Label images should be png images where pixel values represents class number.

    find images -name *.jpg &gt; images.txt
    find labels -name *.png &gt; labels.txt

    for a file name 2011_002920.jpg, each row should contain 2011_002920

    file_path: location of train.txt, or val.txt in PASCAL VOC2012 format,
        listing image file path components without extension
    data_dir: location of image files referred to by file in file_path
    label_dir: location of label files
    data_suffix: image file extension, such as `.jpg` or `.png`
    label_suffix: label file suffix, such as `.png`, or `.npy`
    loss_shape: shape to use when applying loss function to the label data
    &#39;&#39;&#39;

    def __init__(self, file_path, seg_data_generator,
                 data_dir, data_suffix,
                 label_dir, label_suffix, classes, ignore_label=255,
                 crop_mode=&#39;none&#39;, label_cval=255, pad_size=None,
                 target_size=None, color_mode=&#39;rgb&#39;,
                 data_format=&#39;default&#39;, class_mode=&#39;sparse&#39;,
                 batch_size=1, shuffle=True, seed=None,
                 save_to_dir=None, save_prefix=&#39;&#39;, save_format=&#39;jpeg&#39;,
                 loss_shape=None):
        if data_format == &#39;default&#39;:
            data_format = K.image_data_format()
        self.file_path = file_path
        self.data_dir = data_dir
        self.data_suffix = data_suffix
        self.label_suffix = label_suffix
        self.label_dir = label_dir
        self.classes = classes
        self.seg_data_generator = seg_data_generator
        self.target_size = tuple(target_size)
        self.ignore_label = ignore_label
        self.crop_mode = crop_mode
        self.label_cval = label_cval
        self.pad_size = pad_size
        if color_mode not in {&#39;rgb&#39;, &#39;grayscale&#39;}:
            raise ValueError(&#39;Invalid color mode:&#39;, color_mode,
                             &#39;; expected &#34;rgb&#34; or &#34;grayscale&#34;.&#39;)
        self.color_mode = color_mode
        self.data_format = data_format
        self.nb_label_ch = 1
        self.loss_shape = loss_shape

        if (self.label_suffix == &#39;.npy&#39;) or (self.label_suffix == &#39;npy&#39;):
            self.label_file_format = &#39;npy&#39;
        else:
            self.label_file_format = &#39;img&#39;
        if target_size:
            if self.color_mode == &#39;rgb&#39;:
                if self.data_format == &#39;channels_last&#39;:
                    self.image_shape = self.target_size + (3,)
                else:
                    self.image_shape = (3,) + self.target_size
            else:
                if self.data_format == &#39;channels_last&#39;:
                    self.image_shape = self.target_size + (1,)
                else:
                    self.image_shape = (1,) + self.target_size
            if self.data_format == &#39;channels_last&#39;:
                self.label_shape = self.target_size + (self.nb_label_ch,)
            else:
                self.label_shape = (self.nb_label_ch,) + self.target_size
        elif batch_size != 1:
            raise ValueError(
                &#39;Batch size must be 1 when target image size is undetermined&#39;)
        else:
            self.image_shape = None
            self.label_shape = None
        if class_mode not in {&#39;sparse&#39;, None}:
            raise ValueError(&#39;Invalid class_mode:&#39;, class_mode,
                             &#39;; expected one of &#39;
                             &#39;&#34;sparse&#34;, or None.&#39;)
        self.class_mode = class_mode
        if save_to_dir:
            self.palette = None
        self.save_to_dir = save_to_dir
        self.save_prefix = save_prefix
        self.save_format = save_format

        white_list_formats = {&#39;png&#39;, &#39;jpg&#39;, &#39;jpeg&#39;, &#39;bmp&#39;, &#39;npy&#39;}

        # build lists for data files and label files
        self.data_files = []
        self.label_files = []
        fp = open(file_path)
        lines = fp.readlines()
        fp.close()
        self.nb_sample = len(lines)
        for line in lines:
            line = line.strip(&#39;\n&#39;)
            self.data_files.append(line + data_suffix)
            self.label_files.append(line + label_suffix)
        super(SegDirectoryIterator, self).__init__(
            self.nb_sample, batch_size, shuffle, seed)

    def _get_batches_of_transformed_samples(self, index_array):
        &#34;&#34;&#34;Gets a batch of transformed samples.
        # Arguments
            index_array: array of sample indices to include in batch.
        # Returns
            A batch of transformed samples.
        &#34;&#34;&#34;
        current_batch_size = len(index_array)

        # The transformation of images is not under thread lock so it can be
        # done in parallel
        if self.target_size:
            # TODO(ahundt) make dtype properly configurable
            batch_x = np.zeros((current_batch_size,) + self.image_shape)
            if self.loss_shape is None and self.label_file_format is &#39;img&#39;:
                batch_y = np.zeros((current_batch_size,) + self.label_shape,
                                   dtype=int)
            elif self.loss_shape is None:
                batch_y = np.zeros((current_batch_size,) + self.label_shape)
            else:
                batch_y = np.zeros((current_batch_size,) + self.loss_shape,
                                   dtype=np.uint8)
        grayscale = self.color_mode == &#39;grayscale&#39;
        # build batch of image data and labels
        for i, j in enumerate(index_array):
            data_file = self.data_files[j]
            label_file = self.label_files[j]
            img_file_format = &#39;img&#39;
            img = load_img(os.path.join(self.data_dir, data_file),
                           grayscale=grayscale, target_size=None)
            label_filepath = os.path.join(self.label_dir, label_file)

            if self.label_file_format == &#39;npy&#39;:
                y = np.load(label_filepath)
            else:
                label = Image.open(label_filepath)
                if self.save_to_dir and self.palette is None:
                    self.palette = label.palette

            # do padding
            if self.target_size:
                if self.crop_mode != &#39;none&#39;:
                    x = img_to_array(img, data_format=self.data_format)
                    if self.label_file_format is not &#39;npy&#39;:
                        y = img_to_array(
                            label, data_format=self.data_format).astype(int)
                    img_w, img_h = img.size
                    if self.pad_size:
                        pad_w = max(self.pad_size[1] - img_w, 0)
                        pad_h = max(self.pad_size[0] - img_h, 0)
                    else:
                        pad_w = max(self.target_size[1] - img_w, 0)
                        pad_h = max(self.target_size[0] - img_h, 0)
                    if self.data_format == &#39;channels_first&#39;:
                        x = np.lib.pad(x, ((0, 0), (pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2)), &#39;constant&#39;, constant_values=0.)
                        y = np.lib.pad(y, ((0, 0), (pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2)),
                                       &#39;constant&#39;, constant_values=self.label_cval)
                    elif self.data_format == &#39;channels_last&#39;:
                        x = np.lib.pad(x, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)), &#39;constant&#39;, constant_values=0.)
                        y = np.lib.pad(y, ((pad_h // 2, pad_h - pad_h // 2), (pad_w // 2, pad_w - pad_w // 2), (0, 0)), &#39;constant&#39;, constant_values=self.label_cval)
                else:
                    x = img_to_array(img.resize((self.target_size[1], self.target_size[0]),
                                                Image.BILINEAR),
                                     data_format=self.data_format)
                    if self.label_file_format is not &#39;npy&#39;:
                        y = img_to_array(label.resize((self.target_size[1], self.target_size[
                                         0]), Image.NEAREST), data_format=self.data_format).astype(int)
                    else:
                        print(&#39;ERROR: resize not implemented for label npy file&#39;)

            if self.target_size is None:
                batch_x = np.zeros((current_batch_size,) + x.shape)
                if self.loss_shape is not None:
                    batch_y = np.zeros((current_batch_size,) + self.loss_shape)
                else:
                    batch_y = np.zeros((current_batch_size,) + y.shape)

            x, y = self.seg_data_generator.random_transform(x, y)
            x = self.seg_data_generator.standardize(x)

            if self.ignore_label:
                y[np.where(y == self.ignore_label)] = self.classes

            if self.loss_shape is not None:
                y = np.reshape(y, self.loss_shape)

            batch_x[i] = x
            batch_y[i] = y
        # optionally save augmented images to disk for debugging purposes
        if self.save_to_dir:
            for i in range(current_batch_size):
                img = array_to_img(batch_x[i], self.data_format, scale=True)
                label = batch_y[i][:, :, 0].astype(&#39;uint8&#39;)
                label[np.where(label == self.classes)] = self.ignore_label
                label = Image.fromarray(label, mode=&#39;P&#39;)
                label.palette = self.palette
                # TODO(ahundt) fix index=i, a hacky workaround since current_index + i is no long available
                fname = &#39;{prefix}_{index}_{hash}&#39;.format(prefix=self.save_prefix,
                                                         index=i,
                                                         hash=np.random.randint(1e4))
                img.save(os.path.join(self.save_to_dir, &#39;img_&#39; +
                                      fname + &#39;.{format}&#39;.format(format=self.save_format)))
                label.save(os.path.join(self.save_to_dir,
                                        &#39;label_&#39; + fname + &#39;.png&#39;))
        # return
        batch_x = preprocess_input(batch_x)
        if self.class_mode == &#39;sparse&#39;:
            return batch_x, batch_y
        else:
            return batch_x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.preprocessing.image.Iterator</li>
<li>keras.utils.data_utils.Sequence</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="USTool.utils" href="index.html">USTool.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="USTool.utils.SegDataGenerator.center_crop" href="#USTool.utils.SegDataGenerator.center_crop">center_crop</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.pair_center_crop" href="#USTool.utils.SegDataGenerator.pair_center_crop">pair_center_crop</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.pair_random_crop" href="#USTool.utils.SegDataGenerator.pair_random_crop">pair_random_crop</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.random_crop" href="#USTool.utils.SegDataGenerator.random_crop">random_crop</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator" href="#USTool.utils.SegDataGenerator.SegDataGenerator">SegDataGenerator</a></code></h4>
<ul class="">
<li><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator.fit" href="#USTool.utils.SegDataGenerator.SegDataGenerator.fit">fit</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator.flow_from_directory" href="#USTool.utils.SegDataGenerator.SegDataGenerator.flow_from_directory">flow_from_directory</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator.random_transform" href="#USTool.utils.SegDataGenerator.SegDataGenerator.random_transform">random_transform</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator.set_ch_mean" href="#USTool.utils.SegDataGenerator.SegDataGenerator.set_ch_mean">set_ch_mean</a></code></li>
<li><code><a title="USTool.utils.SegDataGenerator.SegDataGenerator.standardize" href="#USTool.utils.SegDataGenerator.SegDataGenerator.standardize">standardize</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="USTool.utils.SegDataGenerator.SegDirectoryIterator" href="#USTool.utils.SegDataGenerator.SegDirectoryIterator">SegDirectoryIterator</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>